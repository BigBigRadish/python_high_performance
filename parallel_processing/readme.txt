并行处理
通过使用多核进行并行处理，无需处理更快的处理器，就可让程序在给定时间执行更多的计算。将问题划分成独立的子单元，使用多核并行处理。
主要内容：
并行处理原理
使用pyhton库multiprocessing并行处理简单问题
使用接口ProcessPoolExecutor
通过Cython和openMP使用多线程进行并行编程
使用theano和tensorflow自动实现并行性
使用Theano，Tensorflow和numba在GPU中执行代码
一.并行处理原理
要让程序并行的运行，必须将问题划分为可彼此独立运行的子单元。如果一个问题的各个子单元是完全彼此独立的，这个问题就是高度并行的。
进程间通信开销非常高，可能严重影响并行性，在并行程序中，处理数据通信的方式有两种：共享内存，分布式内存。
在共享内存中，各个子单元访问相同的内存空间。这种方法的优点是无需显示地处理通信。然而多个进程试图同时访问并修改相同的内存单元，将会出现问题，因此，必须使用同步技术避免这样的冲突。
在分布式内存模型中，每个进程都与其他进程完全分开，并由自己的内存空间，必须显示处理进程间的通信。
以共享内存方式实现并行的一种常见方式是使用线程。线程是进程的独立子任务，共享内存等资源。线程生成多个执行上下文并共享空间，而进程提供多个上下文，必须显示处理通信。
python能够生成并处理线程，但使用线程不能改善性能。由于python解释器的设计，每次只有一个python指令在运行，这种机制称为全局解释器锁。每当线程执行python语句，都获取一个锁，完事儿之后再释放。
有些python实现没有使用GIL，如Jython和IronPython。
通过使用进程可以完全避开GIL，每个进程都有自己的解释器。进程缺点：启动新进程通常比线程慢，消耗的内存更多。进程间通信速度更慢。灵活性更高，可伸缩性更佳。
(2.图形处理单元)GPU
GPU是为了高效的运行与图形相关的操作而设计的，这是通过采用高度并行的体系结构来实现的。
GPU专门用于执行浮点运算。使用特殊编程平台CUDA和openCL。
cuda(COMPUTE UNIFIED DEVICE ARCHITECTURE),是NVIDIA专用技术。CUDA提供工具NVCC，可用来编译使用CUDAc语言编写的GPU程序。
OPENCL是一种开放技术，使用它编写的并行程序可针对各种目标平台进行编译，对非nvida设备来说，这是个好平台。
gpu编程两大挑战：1.将数据写入内存以及从内存读取数据的成本2.实现算法以充分发挥GPU体系结构的作用。
GPU可极大地提高单位时间内可执行的操作数(吞吐量)，需要更多时间准备数据。cpu生成单个结果更快。
